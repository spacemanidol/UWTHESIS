@article{Sun2019ERNIE2A,
  title={ERNIE 2.0: A Continual Pre-training Framework for Language Understanding},
  author={Yu Sun and Shuohuan Wang and Yukun Li and Shikun Feng and Hao Tian and Hua Wu and Haifeng Wang},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.12412}
}
@inproceedings{Howard2018UniversalLM,
  title={Universal Language Model Fine-tuning for Text Classification},
  author={J. Howard and Sebastian Ruder},
  booktitle={ACL},
  year={2018}
}
@article{Taylor1953ClozePA,
  title={“Cloze Procedure”: A New Tool for Measuring Readability},
  author={W. L. Taylor},
  journal={Journalism  Mass Communication Quarterly},
  year={1953},
  volume={30},
  pages={415 - 433}
}
@article{Wu2016GooglesNM,
  title={Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation},
  author={Y. Wu and Mike Schuster and Z. Chen and Quoc V. Le and Mohammad Norouzi and Wolfgang Macherey and M. Krikun and Yuan Cao and Q. Gao and Klaus Macherey and Jeff Klingner and Apurva Shah and M. Johnson and X. Liu and L. Kaiser and S. Gouws and Y. Kato and Taku Kudo and H. Kazawa and K. Stevens and G. Kurian and Nishant Patil and W. Wang and C. Young and J. Smith and Jason Riesa and Alex Rudnick and Oriol Vinyals and G. S. Corrado and Macduff Hughes and J. Dean},
  journal={ArXiv},
  year={2016},
  volume={abs/1609.08144}
}
@inproceedings{McCann2017LearnedIT,
  title={Learned in Translation: Contextualized Word Vectors},
  author={Bryan McCann and James Bradbury and Caiming Xiong and Richard Socher},
  booktitle={NIPS},
  year={2017}
}
@article{Elman1993LearningAD,
  title={Learning and development in neural networks: the importance of starting small},
  author={J. Elman},
  journal={Cognition},
  year={1993},
  volume={48},
  pages={71-99}
}
@article{Vaswani2017AttentionIA,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and L. Kaiser and Illia Polosukhin},
  journal={ArXiv},
  year={2017},
  volume={abs/1706.03762}
}
@inproceedings{Pennington2014GloveGV,
  title={Glove: Global Vectors for Word Representation},
  author={Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle={EMNLP},
  year={2014}
}
@inproceedings{Peters2019KnowledgeEC,
  title={Knowledge Enhanced Contextual Word Representations},
  author={Matthew E. Peters and Mark Neumann and IV RobertLLogan and Roy Schwartz and Vidur Joshi and Sameer Singh and Noah A. Smith},
  booktitle={EMNLP/IJCNLP},
  year={2019}
}
@inproceedings{Strubell2019EnergyAP,
  title={Energy and Policy Considerations for Deep Learning in NLP},
  author={Emma Strubell and Ananya Ganesh and Andrew McCallum},
  booktitle={ACL},
  year={2019}
}
@inproceedings{Devlin2019BERTPO,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  booktitle={NAACL-HLT},
  year={2019}
}
@article{Dai2019TransformerXLAL,
  title={Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context},
  author={Zihang Dai and Z. Yang and Yiming Yang and J. Carbonell and Quoc V. Le and R. Salakhutdinov},
  journal={ArXiv},
  year={2019},
  volume={abs/1901.02860}
}
@inproceedings{Radford2019LanguageMA,
  title={Language Models are Unsupervised Multitask Learners},
  author={A. Radford and Jeffrey Wu and R. Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019}
}
@article{Brown2020LanguageMA,
  title={Language Models are Few-Shot Learners},
  author={T. Brown and B. Mann and Nick Ryder and Melanie Subbiah and J. Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and G. Kr{\"u}ger and Tom Henighan and R. Child and Aditya Ramesh and D. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and E. Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and J. Clark and Christopher Berner and Sam McCandlish and A. Radford and Ilya Sutskever and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.14165}
}
@article{Sanh2019DistilBERTAD,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.01108}
}
@article{Zhou2020HULKAE,
  title={HULK: An Energy Efficiency Benchmark Platform for Responsible Natural Language Processing},
  author={Xiyou Zhou and Zhiyu Chen and Xiaoyong Jin and W. Wang},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.05829}
}
@article{Wynter2020OptimalSE,
  title={Optimal Subarchitecture Extraction For BERT},
  author={Adrian de Wynter and D. Perry},
  journal={ArXiv},
  year={2020},
  volume={abs/2010.10499}
}
@article{Yu2017ScalpelCD,
  title={Scalpel: Customizing DNN pruning to the underlying hardware parallelism},
  author={Jiecao Yu and Andrew Lukefahr and D. Palframan and Ganesh S. Dasika and R. Das and S. Mahlke},
  journal={2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA)},
  year={2017},
  pages={548-560}
}
@article{Han2016DeepCC,
  title={Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding},
  author={Song Han and Huizi Mao and W. Dally},
  journal={CoRR},
  year={2016},
  volume={abs/1510.00149}
}

@article{Sun2019ERNIEER,
  title={ERNIE: Enhanced Representation through Knowledge Integration},
  author={Yu Sun and Shuohuan Wang and Yukun Li and Shikun Feng and Xuyi Chen and Han Zhang and Xin Tian and Danxiang Zhu and Hao Tian and Hua Wu},
  journal={ArXiv},
  year={2019},
  volume={abs/1904.09223}
}
@article{Wang2019SuperGLUEAS,
  title={SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems},
  author={Alex Wang and Yada Pruksachatkun and Nikita Nangia and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.00537}
} 
@inproceedings{Dolan2005AutomaticallyCA,
  title={Automatically Constructing a Corpus of Sentential Paraphrases},
  author={W. Dolan and Chris Brockett},
  booktitle={IWP@IJCNLP},
  year={2005}
}
@inproceedings{Levesque2011TheWS,
  title={The Winograd Schema Challenge},
  author={H. Levesque and E. Davis and L. Morgenstern},
  booktitle={KR},
  year={2011}
}
@article{Pruksachatkun2020jiantAS,
  title={jiant: A Software Toolkit for Research on General-Purpose Text Understanding Models},
  author={Yada Pruksachatkun and Phil Yeres and Haokun Liu and Jason Phang and Phu Mon Htut and Alex Wang and Ian Tenney and Samuel R. Bowman},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.02249}
}
@inproceedings{Dagan2005ThePR,
  title={The PASCAL Recognising Textual Entailment Challenge},
  author={I. Dagan and Oren Glickman and B. Magnini},
  booktitle={MLCW},
  year={2005}
}
@inproceedings{BarHaim2006TheSP,
  title={The Second PASCAL Recognising Textual Entailment Challenge},
  author={Roy Bar-Haim and I. Dagan and B. Dolan and Lisa Ferro and Danilo Giampiccolo and B. Magnini},
  year={2006}
}
@inproceedings{Bentivogli2009TheSP,
  title={The Sixth PASCAL Recognizing Textual Entailment Challenge},
  author={L. Bentivogli and Peter Clark and I. Dagan and Danilo Giampiccolo},
  booktitle={TAC},
  year={2009}
}
@article{Frankle2019TheLT,
  title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
  author={Jonathan Frankle and Michael Carbin},
  journal={arXiv: Learning},
  year={2019}
}
@inproceedings{Giampiccolo2007TheTP,
  title={The Third PASCAL Recognizing Textual Entailment Challenge},
  author={Danilo Giampiccolo and B. Magnini and I. Dagan and W. Dolan},
  booktitle={ACL-PASCAL@ACL},
  year={2007}
}
@article{Williams2018ABC,
  title={A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference},
  author={Adina Williams and Nikita Nangia and Samuel R. Bowman},
  journal={ArXiv},
  year={2018},
  volume={abs/1704.05426}
}
@article{Cer2017SemEval2017T1,
  title={SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation},
  author={Daniel Matthew Cer and Mona T. Diab and Eneko Agirre and I. Lopez-Gazpio and Lucia Specia},
  journal={ArXiv},
  year={2017},
  volume={abs/1708.00055}
}
@article{Warstadt2019NeuralNA,
  title={Neural Network Acceptability Judgments},
  author={Alex Warstadt and Amanpreet Singh and Samuel R. Bowman},
  journal={Transactions of the Association for Computational Linguistics},
  year={2019},
  volume={7},
  pages={625-641}
}
@inproceedings{Socher2013RecursiveDM,
  title={Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank},
  author={R. Socher and Alex Perelygin and J. Wu and Jason Chuang and Christopher D. Manning and A. Ng and Christopher Potts},
  booktitle={EMNLP},
  year={2013}
}
@article{Liang2020XGLUEAN,
  title={XGLUE: A New Benchmark Dataset for Cross-lingual Pre-training, Understanding and Generation},
  author={Yaobo Liang and N. Duan and Yeyun Gong and N. Wu and Fenfei Guo and Weizhen Qi and Ming Gong and Linjun Shou and Daxin Jiang and G. Cao and Xiaodong Fan and Bruce Zhang and Rahul Agrawal and Edward Cui and Sining Wei and Taroon Bharti and Ying Qiao and Jiun-Hung Chen and Winnie Wu and S. Liu and Fan Yang and Rangan Majumder and M. Zhou},
  journal={ArXiv},
  year={2020},
  volume={abs/2004.01401}
}
@article{Hu2020XTREMEAM,
  title={XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual Generalization},
  author={J. Hu and Sebastian Ruder and Aditya Siddhant and Graham Neubig and Orhan Firat and M. Johnson},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.11080}
}
@inproceedings{Shannon1951PredictionAE,
  title={Prediction and entropy of printed English},
  author={Claude E. Shannon},
  year={1951}
}
@article{Zhang2019CurriculumLF,
  title={Curriculum Learning for Domain Adaptation in Neural Machine Translation},
  author={Xuan Zhang and Pamela Shapiro and Manish Kumar and P. McNamee and Marine Carpuat and Kevin Duh},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.05816}
}
@article{Wang2019LearningAM,
  title={Learning a Multitask Curriculum for Neural Machine Translation},
  author={Wei Wang and Ye Tian and J. Ngiam and Yinfei Yang and Isaac Caswell and Zarana Parekh},
  journal={ArXiv},
  year={2019},
  volume={abs/1908.10940}
}
@article{Talmor2019oLMpicsO,
  title={oLMpics - On what Language Model Pre-training Captures},
  author={Alon Talmor and Yanai Elazar and Yoav Goldberg and Jonathan Berant},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.13283}
}
@inproceedings{Settles2009ActiveLL,
  title={Active Learning Literature Survey},
  author={Burr Settles},
  year={2009}
}
@article{Merity2016PointerSM,
  title={Pointer Sentinel Mixture Models},
  author={Stephen Merity and Caiming Xiong and James Bradbury and Richard Socher},
  journal={ArXiv},
  year={2016},
  volume={abs/1609.07843}
}
@article{Shoeybi2019MegatronLMTM,
  title={Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism},
  author={Mohammad Shoeybi and Mostofa Ali Patwary and Raul Puri and Patrick LeGresley and Jared Casper and Bryan Catanzaro},
  journal={ArXiv},
  year={2019},
  volume={abs/1909.08053}
}
@inproceedings{Kocmi2017CurriculumLA,
  title={Curriculum Learning and Minibatch Bucketing in Neural Machine Translation},
  author={Tom Kocmi and Ondrej Bojar},
  booktitle={RANLP},
  year={2017}
}
@article{Sutton1998ReinforcementLA,
  title={Reinforcement Learning: An Introduction},
  author={Richard S. Sutton and Andrew G. Barto},
  journal={IEEE Transactions on Neural Networks},
  year={1998},
  volume={16},
  pages={285-286}
}
@article{Sharir2020TheCO,
  title={The Cost of Training NLP Models: A Concise Overview},
  author={Or Sharir and Barak Peleg and Yoav Shoham},
  journal={ArXiv},
  year={2020},
  volume={abs/2004.08900}
}
@article{Hochreiter1997LongSM,
  title={Long Short-Term Memory},
  author={Sepp Hochreiter and J{\"u}rgen Schmidhuber},
  journal={Neural Computation},
  year={1997},
  volume={9},
  pages={1735-1780}
}
@article{Platanios2019CompetencebasedCL,
  title={Competence-based Curriculum Learning for Neural Machine Translation},
  author={Emmanouil Antonios Platanios and Otilia Stretcu and Graham Neubig and Barnab{\'a}s P{\'o}czos and Tom Michael Mitchell},
  journal={ArXiv},
  year={2019},
  volume={abs/1903.09848}
}
@article{Chelba2014OneBW,
  title={One billion word benchmark for measuring progress in statistical language modeling},
  author={Ciprian Chelba and Tomas Mikolov and Michael Schuster and Qi Ge and Thorsten Brants and Phillipp Koehn and Tony Robinson},
  journal={ArXiv},
  year={2014},
  volume={abs/1312.3005}
}
@article{Kaplan2020ScalingLF,
  title={Scaling Laws for Neural Language Models},
  author={Jean Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2001.08361}
}
@inproceedings{Kiros2015SkipThoughtV,
  title={Skip-Thought Vectors},
  author={Ryan Kiros and Yukun Zhu and Ruslan Salakhutdinov and Richard S. Zemel and Raquel Urtasun and Antonio Torralba and Sanja Fidler},
  booktitle={NIPS},
  year={2015}
}
@article{Bojanowski2017EnrichingWV,
  title={Enriching Word Vectors with Subword Information},
  author={Piotr Bojanowski and Edouard Grave and Armand Joulin and Tomas Mikolov},
  journal={Transactions of the Association for Computational Linguistics},
  year={2017},
  volume={5},
  pages={135-146}
}
@inproceedings{Hu2016DifferentCL,
  title={Different Contexts Lead to Different Word Embeddings},
  author={Wenpeng Hu and Jiajun Zhang and Nan Zheng},
  booktitle={COLING},
  year={2016}
}
@article{Le2014DistributedRO,
  title={Distributed Representations of Sentences and Documents},
  author={Quoc V. Le and Tomas Mikolov},
  journal={ArXiv},
  year={2014},
  volume={abs/1405.4053}
}
@inproceedings{Leacock1993TowardsBC,
  title={Towards Building Contextual Representations Of Word Senses Using Statistical Models},
  author={Claudia Leacock and Geoffrey G. Towell and Ellen M. Voorhees},
  year={1993}
}
@article{Goodfellow2014GenerativeAN,
  title={Generative Adversarial Networks},
  author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron C. Courville and Yoshua Bengio},
  journal={ArXiv},
  year={2014},
  volume={abs/1406.2661}
}
@article{Clark2020ELECTRAPT,
  title={ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators},
  author={Kevin Clark and Minh-Thang Luong and Quoc V. Le and Christopher D. Manning},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.10555}
}
@article{Lewis2019BARTDS,
  title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  author={Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Ves Stoyanov and Luke Zettlemoyer},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.13461}
}
@article{Cohn1994ActiveLW,
  title={Active Learning with Statistical Models},
  author={David A. Cohn and Zoubin Ghahramani and Michael I. Jordan},
  journal={J. Artif. Intell. Res.},
  year={1994},
  volume={4},
  pages={129-145}
}
@article{Guo2019FineTuningBC,
  title={Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation},
  author={Junliang Guo and Xu Tan and Linli Xu and Tao Qin and Enhong Chen and Tie-Yan Liu},
  journal={ArXiv},
  year={2019},
  volume={abs/1911.08717}
}
@inproceedings{Kano2017StructuredBasedCL,
  title={Structured-Based Curriculum Learning for End-to-End English-Japanese Speech Translation},
  author={Takatomo Kano and Sakriani Sakti and Satoshi Nakamura},
  booktitle={INTERSPEECH},
  year={2017}
}
@article{Karras2017ProgressiveGO,
  title={Progressive Growing of GANs for Improved Quality, Stability, and Variation},
  author={Tero Karras and Timo Aila and Samuli Laine and Jaakko Lehtinen},
  journal={ArXiv},
  year={2017},
  volume={abs/1710.10196}
}
@inproceedings{Tran2020SubsetSF,
  title={Subset Sampling For Progressive Neural Network Learning},
  author={Dat Thanh Tran and Moncef Gabbouj and Alexandros Iosifidis},
  year={2020}
}
@article{Berger1996AME,
  title={A Maximum Entropy Approach to Natural Language Processing},
  author={Adam L. Berger and Stephen Della Pietra and Vincent J. Della Pietra},
  journal={Computational Linguistics},
  year={1996},
  volume={22},
  pages={39-71}
}
@article{Chatterjee2017ProgressiveLF,
  title={Progressive Learning for Systematic Design of Large Neural Networks},
  author={Saikat Chatterjee and Alireza M. Javid and Mostafa Sadeghi and Partha P. Mitra and Mikael Skoglund},
  journal={ArXiv},
  year={2017},
  volume={abs/1710.08177}
}
@inproceedings{Bengio2009CurriculumL,
  title={Curriculum learning},
  author={Yoshua Bengio and J{\'e}r{\^o}me Louradour and Ronan Collobert and Jason Weston},
  booktitle={ICML '09},
  year={2009}
}
@inproceedings{Yang2019XLNetGA,
  title={XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  author={Zhilin Yang and Zihang Dai and Yiming Yang and Jaime G. Carbonell and Ruslan Salakhutdinov and Quoc V. Le},
  booktitle={NeurIPS},
  year={2019}
}
@article{Liu2019RoBERTaAR,
  title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.11692}
}
@inproceedings{Radford2018ImprovingLU,
  title={Improving Language Understanding by Generative Pre-Training},
  author={Alec Radford},
  year={2018}
}
@article{Joshi2019SpanBERTIP,
  title={SpanBERT: Improving Pre-training by Representing and Predicting Spans},
  author={Mandar Joshi and Danqi Chen and Yinhan Liu and Daniel S. Weld and Luke Zettlemoyer and Omer Levy},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.10529}
}
@article{Nogueira2019MultiStageDR,
  title={Multi-Stage Document Ranking with BERT},
  author={Rodrigo Nogueira and Wei Yang and Kyunghyun Cho and Jimmy Lin},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.14424}
}
@inproceedings{Wang2018GLUEAM,
  title={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
  author={Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
  booktitle={BlackboxNLP@EMNLP},
  year={2018}
}
@article{Clark2019WhatDB,
  title={What Does BERT Look At? An Analysis of BERT's Attention},
  author={Kevin Clark and Urvashi Khandelwal and Omer Levy and Christopher D. Manning},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.04341}
}
@inproceedings{Liu2019LinguisticKA,
  title={Linguistic Knowledge and Transferability of Contextual Representations},
  author={Nelson F. Liu and Matt Gardner and Yonatan Belinkov and Matthew E. Peters and Noah A. Smith},
  booktitle={NAACL-HLT},
  year={2019}
}
@article{Lan2019ALBERTAL,
  title={ALBERT: A Lite BERT for Self-supervised Learning of Language Representations},
  author={Zhen-Zhong Lan and Mingda Chen and Sebastian Goodman and Kevin Gimpel and Piyush Sharma and Radu Soricut},
  journal={ArXiv},
  year={2019},
  volume={abs/1909.11942}
}
@article{Smith2019ContextualWR,
  title={Contextual Word Representations: A Contextual Introduction},
  author={Noah A. Smith},
  journal={ArXiv},
  year={2019},
  volume={abs/1902.06006}
}
@article{Miller1992WordNetAL,
  title={WordNet: a lexical database for English},
  author={George A. Miller},
  journal={Commun. ACM},
  year={1992},
  volume={38},
  pages={39-41}
}
@article{Athiwaratkun2017MultimodalWD,
  title={Multimodal Word Distributions},
  author={Ben Athiwaratkun and Andrew Gordon Wilson},
  journal={ArXiv},
  year={2017},
  volume={abs/1704.08424}
}
@inproceedings{You2019LargeBO,
  title={Large Batch Optimization for Deep Learning: Training BERT in 76 minutes.},
  author={Yang You and Jing Li and Sashank J. Reddi and Jonathan Hseu and Sanjiv Kumar and Srinadh Bhojanapalli and Xiaodan Song and James Demmel and Kurt Keutzer and Cho-Jui Hsieh},
  year={2019}
}
@article{Mikolov2013EfficientEO,
  title={Efficient Estimation of Word Representations in Vector Space},
  author={Tomas Mikolov and Kai Chen and Gregory S. Corrado and Jeffrey Dean},
  journal={CoRR},
  year={2013},
  volume={abs/1301.3781}
}
@article{Weizenbaum1966ELIZAA,
  title={ELIZA — a computer program for the study of natural language communication between man and machine},
  author={Joseph Weizenbaum},
  journal={Commun. ACM},
  year={1966},
  volume={26},
  pages={23-28}
}
@inproceedings{opennmt,
  author    = {Guillaume Klein and
               Yoon Kim and
               Yuntian Deng and
               Jean Senellart and
               Alexander M. Rush},
  title     = {OpenNMT: Open-Source Toolkit for Neural Machine Translation},
  booktitle = {Proc. ACL},
  year      = {2017},
  url       = {https://doi.org/10.18653/v1/P17-4012},
  doi       = {10.18653/v1/P17-4012}
}

@misc{Rosset2020TNLG,
    author = {Corby Rosset},
    title = {Turing-NLG: A 17-billion-parameter language model by Microsoft},
    year = {2020}
}
@article{Bahdanau2014NeuralMT,
  title={Neural Machine Translation by Jointly Learning to Align and Translate},
  author={Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
  journal={CoRR},
  year={2014},
  volume={abs/1409.0473}
}
@inproceedings{Rajpurkar2016SQuAD10,
  title={SQuAD: 100, 000+ Questions for Machine Comprehension of Text},
  author={Pranav Rajpurkar and Jian Zhang and Konstantin Lopyrev and Percy Liang},
  booktitle={EMNLP},
  year={2016}
}

@inproceedings{Luong2015EffectiveAT,
  title={Effective Approaches to Attention-based Neural Machine Translation},
  author={Thang Luong and Hieu Pham and Christopher D. Manning},
  booktitle={EMNLP},
  year={2015}
}
@inproceedings{McCallum2000MaximumEM,
  title={Maximum Entropy Markov Models for Information Extraction and Segmentation},
  author={Andrew McCallum and Dayne Freitag and Fernando C Pereira},
  booktitle={ICML},
  year={2000}
}
@article{Peters2018DeepCW,
  title={Deep Contextualized Word Representations},
  author={Matthew E. Peters and Mark Neumann and Mohit Iyyer and Matt Gardner and Christopher Clark and Kenton Lee and Luke Zettlemoyer},
  journal={ArXiv},
  year={2018},
  volume={abs/1802.05365}
}