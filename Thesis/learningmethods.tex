\section{Learning Methods}
In this section, we first briefly review some leaning methodologies for neural network in section 3.1.1 so as to formalize what learning methods seek to achieve. Then, in section 3.1.2 we introduce Curriculum learning and describe a few implementation related to NLP. 
\subsection{Brief Overview of learning methodologies}
Neural Networks are usually trained by randomly selecting batches of data in a training corpus. This method is an extremely effective way of producing a model that represents the data but can at times be cost/compute prohibitive and some problem formalization's do not work well with methodology. Methods like Curriculum Learning \cite{Bengio2009CurriculumL}, reinforcement learning \cite{Sutton1998ReinforcementLA}, and active learning \cite{Cohn1994ActiveLW} have been used across many domains to speed up model training and accuracy. Most methods, at their core seek to optimize what kind of information a model has access to at each step in training with the goal of allowing it to find better gradients than a random sample. In domains like Generative Adversarial Networks(GAN) \cite{Goodfellow2014GenerativeAN} training models that generate large images has proven difficult. Seeing structure in the size of images, researchers have found tremendous improvements in training models with progressively more complex data. Unlike previous approaches and most traditional machine learned methods, Progressively trains models by increasing the size of the target output as training progresses\cite{Karras2017ProgressiveGO}. Unlike previous approaches and most traditional machine learned methods, Progressively trains models by increasing the size of the target output as training progresses. Initially, the Generator is generator is producing 2x2 pixel images. Once it and the Discriminator converge, the target output size is increased. This progressive training continues until the Generator is producing 4096 x 4096 images. By training in an increasingly entropic way, the Generator is able to continually learn an increasingly complex goal. By training progressively the final model is able to learn a better representation with a higher sample efficiency. This work on progressive learning in GANS is what inspired this dissertation as LM, much like GANs, are conceptually simple but can prove difficult to train at scale. 
\subsection{Curriculum Learning}
While curriculum learning first formalized its introduction into the computer science in 2009 \cite{Bengio2009CurriculumL} the concept of CL is much older and originating outside of computer science. At its core the concept of CL is the idea of choosing examples to be presented in a specific order so as to guide a the agent seeing said examples to learn quicker. Early experiments \cite{Elman1993LearningAD} with RNNs focused on learning grammar suggested that learning of complex grammatical structure improves when the initial examples the models learn with are simpler. CL guides the optimization process to converge faster and guide the learner to a better local minimal and can generally be thought of a method of re-weighting the training distribution over the course of model training. Unlike CL, regular random batch sampling emphasizes an equal contribution of each data point without any notion of how common the data point is and how general of foundational it is.\\
In the original paper the authors suggest that training with CL approaches may act similarly to  unsupervised pretraining. The authors explore the effect oc CL in three experiments: using a perceptron to learn an equation, shape recognition and language modeling. In their language modeling task they modify the training corpus to make it increasingly difficult. Starting with a corpus of 631m tokens of wikipedia the initially replace any word that is not in the N most common words(starts with 5,000) with an a token to represent unknown workds, '<UNK>'. After each pass on the corpus N is increased by 5,000. After 1 billion updates the CL method has a loss of 2.78 vs the non-CL loss of 2.83. The two main issues in CL are: the computational cost to assemble the batch and the effective amount of data the model can learn from in early epochs is low. \\
Since this original paper CL methods have proven effective for many NLP domains, especially in Neural Machine Translation(NMT). Wang et al. '19 \cite{Wang2019LearningAM} expand on CL as data selection and data augmentation method. Their implementation focuses on selecting data which is relevant to all tasks and disregarding data that may be only relevant to specific domain and is able to bring a 2.5 BLEU point improvement vs non curricula implementation. Platanios et al. 19' introduce the notion of competence base CL which is the basis for much of our experimentation. \cite{Platanios2019CompetencebasedCL}. The authors main contribution is building a CL method, which they called competence curricula, that only controls how long the curriculum lasts before regular training occurs. The authors approach is a 2 step: assign a difficulty value to each sample in the training data, and train the model with increasingly more data as its competence improves. In the first stage a heuristic is applied to rank the training data from easiest to hardest. Using a cumulative density function(CDF) each sample is then given a value $[0,1]$ which equates to how difficult the sample is. Then, starting with some initial competence $\lambda_0$ the model will train by sampling a training batch from the training data where the sample difficulty is lower than the models current competence. After each batch the models competence is increased by some step $\epsilon$ until it is now training on the full dataset. Using this competence curricula method Platanios et al. 19' on NMT the authors are able to reduce training time by 70\% and improve BLEU performance by 2.2 points. The authors explore performance on transformers, BiLSTMs, and BiLSTMs using 2 difficulty metric: sentence length, word rarity(word occurrences over total tokens in corpus) and 2 competence step functions:linear(new samples are constantly introduced at a fixed rate) and Root (sample quickly then slowly to allow model to learn all the new examples) and across all methods find improvement over traditional non-CL sampling.