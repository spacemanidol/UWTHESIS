\section{Architecture}
In this section, we first briefly review of neural networks in NLP in section 2.1.1 so as to obtain insight into how system architecture can effect downstream tasks. Then, in section 2.1.2 we introduce Long Short Term Memory(LSTM) \cite{} and describe how it works. In section 2.1.3 we introduce the transformer \cite{} and briefly discuss how it differs from LSTM. 
\subsection{Neural Network in NLP}
In the last few decades, neural networks have provided language researchers with a effective method of building models which can represent the complex phenomena associated with language. In NLP Recurrent Neural Networks(RNN) have been a popular building block because they can retrain information from previous states of calculation in current state. While useful, RNNs have a short-term memory. With long sequences they are unable to keep relevant information which makes them unable to model long text sequences. This issue arises because during back propagation RNNs are susceptible to what is known as the vanishing gradient problem. The vanishing gradient problem is when gradients shrink during back propagation through time. Eventually the gradient becomes too small and doesn't not contribute to what the RNN can learn. In RNN, since it is difficult to get the gradient of earlier seen information it means RNNs tend to ignore earlier content. Methods like LSTM and the transformer are implementations to get around the vanishing gradient that RNNs experience. 
\subsection{LSTM}
The LSTM was first proposed by Hochreiter et. al 97 \cite{Hochreiter1997LongSM} as a neural method that get around the vanishing gradient problem. LSTMs have gating mechanism which regulate the flow of information from previous states into the current state. What makes the LSTM unique is the gates include trainable parameter which learn what information from previous state to keep and throw away. Using these gates LSTMs can retain relevant information's in a long chain of inputs to make predictions. Since LSTMs excel at data where there is a chain of events they have revolutionized the world of time-series analysis, speech recognition, and machine translation to name a few. 
\subsection{Transformer}
The transformer is a neural system first proposed by Vaswani, et al. 2017  \cite{Vaswani2017AttentionIA} as a system for Neural Machine Translation(NMT). The transformer block was designed to move away from RNNs to an architecture that is only focused on the attention mechanism \cite{}. Attention is a method which is used to selectively attend to items in a given set of data. The attention is a learned weight mechanism which learns to represent how much one item in a list is related others. In NLP this method has been extremely successful as it allows a model to learn the interdependence of terms without any sort of prepossessing. In its initial formulation, the implementation had an encoder-decoder architecture each where each consisted of 6 stacked transformer layers. All encoders are identical(but do not share weights) and has two sub layers: self-attention and a feed forward network. All decoders are identical(and do not share weights) and consist of 3 sub layers: self-attention, encoder-decoder attention, and a feed forward layer. Vaswani, et al. 2017 use multi head attention to produce a linear projection which is used to attend to different parts of the input all at once. Since this method does not rely on recurrence or convolution a positional encoding is introduced to understand where in a sentence a word is. For more details about mechanics of the transformer we recommend reading The Illustrated Transformer\footnote{https://jalammar.github.io/illustrated-transformer/}. Using these stacked layers of transformers the authors are focus on NMT where the train on English-French and English-German translation. Their method allows them to out perform all previous models with roughly 1/4 the training time of prior models. \\
The transformers ability to model long term dependencies well and efficiently has made it a natural fit for most NLP tasks. As we will cover in succeeding sections, researchers have used this method to produce robust and usable language representations.